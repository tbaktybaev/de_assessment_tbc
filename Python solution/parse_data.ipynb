{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing Contracts and Extracting Features\n",
    "\n",
    "In this notebook, we parse a dataset of contracts stored as JSON strings and extract key features for analysis. \n",
    "\n",
    "### Step 1: Parsing Contracts\n",
    "Contracts are stored as JSON strings, which we convert into structured columns. We extract key details like bank names, contract IDs, and claim dates for easier processing.\n",
    "\n",
    "### Step 2: Data Type Conversion\n",
    "We convert dates and numbers into appropriate formats (datetime and numeric) so that we can calculate and analyze them properly.\n",
    "\n",
    "### Step 3: Feature Extraction\n",
    "We compute useful features:\n",
    "- **`tot_claim_cnt_l180d`**: Number of claims in the last 180 days.\n",
    "- **`disb_bank_loan_wo_tbc`**: Sum of loans from non-excluded banks.\n",
    "- **`day_sinlastloan`**: Days since the last loan.\n",
    "\n",
    "Special cases like missing claims or loans are handled with specific values (`-3` or `-1`).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "from pandas.core.frame import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_contracts(data: pd.DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Parses the 'contracts' column in the dataset, which contains JSON strings, into structured columns.\n",
    "    \n",
    "    Steps:\n",
    "    - Sorts data by 'id', 'application_date', and 'contracts' to ensure correct ordering.\n",
    "    - Iterates over each row, converts the JSON contract data into a more readable format.\n",
    "    - Each contract in the JSON is broken down into fields like contract_id, bank, summa, etc.\n",
    "    - Handles potential JSON decoding errors.\n",
    "    \n",
    "    Args:\n",
    "    - data (pd.DataFrame): Input dataframe containing contract data, with 'contracts' as a JSON string column.\n",
    "    Returns:\n",
    "    - pd.DataFrame: A dataframe where each contract is expanded into its own row, with structured columns like 'bank', 'summa', etc.\n",
    "    \"\"\"\n",
    "    data = data.sort_values(by=['id', 'application_date', 'contracts']).drop_duplicates(subset=['contracts'], keep='last')\n",
    "\n",
    "    rows = []\n",
    "    for _, row in data.iterrows():\n",
    "        id_value = row['id']\n",
    "        application_date = row['application_date']\n",
    "        contracts_str = row['contracts']\n",
    "\n",
    "        if pd.isna(contracts_str) or contracts_str == '':\n",
    "            continue\n",
    "        else:\n",
    "            try:\n",
    "                contracts = json.loads(contracts_str)\n",
    "                if isinstance(contracts, dict):\n",
    "                    contracts = [contracts]\n",
    "                for contract in contracts:\n",
    "                    rows.append({\n",
    "                        'id': id_value,\n",
    "                        'application_date': application_date,\n",
    "                        'contract_id': contract.get('contract_id'),\n",
    "                        'bank': contract.get('bank'),\n",
    "                        'summa': contract.get('summa'),\n",
    "                        'loan_summa': contract.get('loan_summa'),\n",
    "                        'claim_date': contract.get('claim_date'),\n",
    "                        'claim_id': contract.get('claim_id'),\n",
    "                        'contract_date': contract.get('contract_date')\n",
    "                    })\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data_types(df: pd.DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Converts important columns to the appropriate data types for further processing.\n",
    "    \n",
    "    Steps:\n",
    "    - Converts 'id' to integer type.\n",
    "    - Converts 'application_date', 'claim_date', and 'contract_date' to datetime format.\n",
    "    - Converts 'summa' and 'loan_summa' to numeric format for calculations.\n",
    "    \n",
    "    Args:\n",
    "    - df (pd.DataFrame): Input dataframe with columns needing type conversion.\n",
    "    Returns:\n",
    "    - pd.DataFrame: Dataframe with corrected types for dates and numeric fields.\n",
    "    \"\"\"\n",
    "    df['id'] = df['id'].astype('Int64')\n",
    "    df['application_date'] = pd.to_datetime(df['application_date'], errors='coerce').dt.tz_localize(None)\n",
    "    df['claim_date'] = pd.to_datetime(df['claim_date'], format='%d.%m.%Y', errors='coerce').dt.tz_localize(None)\n",
    "    df['contract_date'] = pd.to_datetime(df['contract_date'], format='%d.%m.%Y', errors='coerce').dt.tz_localize(None)\n",
    "    df['summa'] = pd.to_numeric(df['summa'], errors='coerce')\n",
    "    df['loan_summa'] = pd.to_numeric(df['loan_summa'], errors='coerce')\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tot_claim_cnt_l180d(df: pd.DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Calculates the total number of claims made within the last 180 days from the 'application_date'.\n",
    "    \n",
    "    Steps:\n",
    "    - For each 'id', calculates how many claims fall within the 180-day window.\n",
    "    - If no valid claims are found, returns -3.\n",
    "    \n",
    "    Args:\n",
    "    - df (pd.DataFrame): Dataframe with claim dates and application dates.\n",
    "    Returns:\n",
    "    - pd.DataFrame: Dataframe with the count of claims in the last 180 days, grouped by 'id'.\n",
    "    \"\"\"\n",
    "    def claims_in_last_180_days(sub_df):\n",
    "        app_date = sub_df['application_date'].iloc[0]\n",
    "        last_180_days = app_date - timedelta(days=180)\n",
    "        valid_claims = sub_df[(sub_df['claim_date'] >= last_180_days) & (sub_df['claim_date'] <= app_date)]\n",
    "        return len(valid_claims) if len(valid_claims) > 0 else -3\n",
    "\n",
    "    return df.groupby('id').apply(claims_in_last_180_days).reset_index(name='tot_claim_cnt_l180d')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_disb_bank_loan_wo_tbc(df: pd.DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Sums the loan amounts from valid banks, excluding certain banks like 'MKO', 'LIZ', etc.\n",
    "    \n",
    "    Steps:\n",
    "    - Excludes loans from specific banks (e.g., 'MKO', 'LIZ', etc.).\n",
    "    - Considers only loans where 'contract_date' is not null (disbursed loans).\n",
    "    - If no valid loans are found, returns -1 or -3 depending on the scenario.\n",
    "    \n",
    "    Args:\n",
    "    - df (pd.DataFrame): Dataframe containing loan data, including bank names and loan amounts.\n",
    "    Returns:\n",
    "    - pd.DataFrame: Dataframe with total loan amounts grouped by 'id' from non-excluded banks.\n",
    "    \"\"\"\n",
    "    excluded_banks = ['LIZ', 'LOM', 'MKO', 'SUG', None]\n",
    "\n",
    "    def sum_loans_wo_tbc(sub_df):\n",
    "        valid_loans = sub_df[(sub_df['bank'].notna()) & (~sub_df['bank'].isin(excluded_banks)) & (sub_df['contract_date'].notna())]\n",
    "        total_sum = valid_loans['loan_summa'].sum()\n",
    "        if len(valid_loans) == 0:\n",
    "            return -1\n",
    "        return total_sum if total_sum > 0 else -3\n",
    "\n",
    "    return df.groupby('id').apply(sum_loans_wo_tbc).reset_index(name='disb_bank_loan_wo_tbc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_day_sinlastloan(df):\n",
    "    \"\"\"\n",
    "    Calculates how many days have passed since the last valid loan (where 'summa' is not null).\n",
    "    \n",
    "    Steps:\n",
    "    - Finds the last valid loan for each 'id' and calculates the difference in days from the 'application_date'.\n",
    "    - If no valid loans are found, returns -1 or -3 depending on the scenario.\n",
    "    \n",
    "    Args:\n",
    "    - df (pd.DataFrame): Dataframe with loan data, including loan amounts and dates.\n",
    "    Returns:\n",
    "    - pd.DataFrame: Dataframe with the number of days since the last loan, grouped by 'id'.\n",
    "    \"\"\"\n",
    "    def days_since_last_loan(sub_df):\n",
    "        valid_loans = sub_df[sub_df['summa'].notna() & (sub_df['summa'] > 0)]\n",
    "        if valid_loans.empty:\n",
    "            return -1\n",
    "        last_loan_date = valid_loans['contract_date'].max()\n",
    "        days_diff = (sub_df['application_date'].iloc[0] - last_loan_date).days\n",
    "        return days_diff if days_diff > 0 else -3\n",
    "\n",
    "    return df.groupby('id').apply(days_since_last_loan).reset_index(name='day_sinlastloan')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "data = parse_contracts(data)\n",
    "data = convert_data_types(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature calculation completed and saved to contract_features.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wp/5j3ybksn7nn0977443cqx8j00000gn/T/ipykernel_90074/1040057382.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby('id').apply(claims_in_last_180_days).reset_index(name='tot_claim_cnt_l180d')\n",
      "/var/folders/wp/5j3ybksn7nn0977443cqx8j00000gn/T/ipykernel_90074/710886507.py:24: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby('id').apply(sum_loans_wo_tbc).reset_index(name='disb_bank_loan_wo_tbc')\n",
      "/var/folders/wp/5j3ybksn7nn0977443cqx8j00000gn/T/ipykernel_90074/2182681657.py:22: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby('id').apply(days_since_last_loan).reset_index(name='day_sinlastloan')\n"
     ]
    }
   ],
   "source": [
    "application_dates = data[['id', 'application_date']].drop_duplicates()\n",
    "\n",
    "tot_claim_cnt_l180d = calculate_tot_claim_cnt_l180d(data)\n",
    "disb_bank_loan_wo_tbc = calculate_disb_bank_loan_wo_tbc(data)\n",
    "day_sinlastloan = calculate_day_sinlastloan(data)\n",
    "\n",
    "features_df = tot_claim_cnt_l180d.merge(disb_bank_loan_wo_tbc, on='id').merge(day_sinlastloan, on='id').merge(application_dates, on='id')\n",
    "\n",
    "columns_order = ['id', 'application_date', 'tot_claim_cnt_l180d', 'disb_bank_loan_wo_tbc', 'day_sinlastloan']\n",
    "features_df = features_df[columns_order]\n",
    "\n",
    "features_df.to_csv('contract_features.csv', index=False)\n",
    "\n",
    "print(\"Feature calculation completed and saved to contract_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данную задачу можно было реализовать несколькими способами:\n",
    "1. Использовать DAG в Airflow для автоматической обработки.\n",
    "2. Создание Python приложения\n",
    "3. Простой подход с помощью Jupyter Notebook для визуального анализа и тестирования.\n",
    "\n",
    "Каждый вариант имеет свои плюсы в зависимости от цели и объема данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
